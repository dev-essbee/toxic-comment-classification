{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import itertools\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional, Dropout, GlobalMaxPool1D, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.load('./processed/train_padded.npy')\n",
    "train_y=np.load('./processed/train_y.npy')\n",
    "val_x=np.load('./processed/val_padded.npy')\n",
    "val_y=np.load('./processed/val_y.npy')\n",
    "train_y_meta=pd.read_csv('../kaggle_data/train_y.csv')\n",
    "val_y_meta=pd.read_csv('../kaggle_data/val_y.csv')\n",
    "word_index=json.load(open('./processed/word_index.json','r'))\n",
    "embedding_matrix_fasttext=np.load('./processed/embedding_matrix_fasttext.npy')\n",
    "maxpadlen=max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../params.json', 'r') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "max_length = params['max_length']\n",
    "padding_type = params['padding_type']\n",
    "vocab_size = params['vocab_size']\n",
    "embedding_dim_fasttext = params['embedding_dim']\n",
    "trunc_type = params['trunc_type']\n",
    "oov_tok = params['oov_tok']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45180, 150)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features=100000\n",
    "# tokenizer = Tokenizer(num_words=max_features)\n",
    "# tokenizer.fit_on_texts(list(processed_train_data))\n",
    "# list_tokenized_train = tokenizer.texts_to_`sequences(processed_train_data)\n",
    "# list_tokenized_val = tokenizer.texts_to_sequences(processed_val_data)\n",
    "# list_tokenized_test = tokenizer.texts_to_sequences(processed_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxpadlen = 200\n",
    "# X_t=pad_sequences(list_tokenized_train, maxlen=maxpadlen, padding = 'post')\n",
    "# X_v=pad_sequences(list_tokenized_val, maxlen=maxpadlen, padding = 'post')\n",
    "# X_te=pad_sequences(list_tokenized_test, maxlen=maxpadlen, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train=X_t\n",
    "# y_train=pd.read_csv('../kaggle_data/train_y.csv')\n",
    "# x_val=X_v\n",
    "# y_val=pd.read_csv('../kaggle_data/val_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_meta=pd.read_csv('../kaggle_data/train_y.csv')\n",
    "val_y_meta=pd.read_csv('../kaggle_data/val_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wga(y,y_pred):\n",
    "    y.loc[:, 'pred'] = y_pred\n",
    "    categories = ['male', 'female', 'LGBTQ', 'christian', 'muslim', 'other_religions', 'black', 'white']\n",
    "    accuracies = []\n",
    "    groups=[]\n",
    "    for category in categories:\n",
    "        for label in [0, 1]:\n",
    "            group = y.loc[y[category] == label]\n",
    "            group_accuracy = (group['y'] == (group['pred'] > 0.5)).mean()\n",
    "            groups.append(category+'_'+str(label))\n",
    "            accuracies.append(group_accuracy)\n",
    "    wga = np.min(accuracies)\n",
    "    return wga, dict(zip(groups,accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batching_columns(val_x,val_meta,model):\n",
    "    val_x = val_x.reshape((val_x.shape[0], -1))\n",
    "    data=tf.data.Dataset.from_tensor_slices((val_x,val_meta))\n",
    "    data=data.batch(32)\n",
    "\n",
    "    predictions, indices = [], []\n",
    "    for idx, (x, y) in tqdm(enumerate(data), leave=False):\n",
    "        pred = model(x, training=False)\n",
    "        predictions.extend(tf.squeeze(pred).numpy().tolist())\n",
    "        indices.extend([idx] * len(y))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorstGroupAccuracy(Callback):\n",
    "    def __init__(self, train_data, val_data):\n",
    "        super(WorstGroupAccuracy, self).__init__()\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_x,_,train_meta = self.train_data\n",
    "        val_x,_,val_meta = self.val_data\n",
    "        \n",
    "        train_y_pred=batching_columns(train_x, train_meta,self.model)\n",
    "        train_wga, train_metric = calculate_wga(train_meta,train_y_pred)\n",
    "        \n",
    "        val_y_pred=batching_columns(val_x,val_meta,self.model)\n",
    "        val_wga,val_metric = calculate_wga(val_meta,val_y_pred)\n",
    "        \n",
    "        print(f'{train_wga},Train WGA: {train_metric}')\n",
    "        print(f'{val_wga},Val WGA: {val_metric}')\n",
    "        \n",
    "wga = WorstGroupAccuracy((train_x,train_y,train_y_meta), (val_x,val_y,val_y_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Input Parameters to the Function.\n",
    "def toxic_classifier(x_train,y_train,x_val,y_val,params):\n",
    "\n",
    "  inp=Input(shape=(maxpadlen, ),dtype='int32')\n",
    "\n",
    "  embedding_layer = Embedding(len(word_index) + 1,\n",
    "                           embedding_dim_fasttext,\n",
    "                           weights = [embedding_matrix_fasttext],\n",
    "                           input_length = maxpadlen,\n",
    "                           trainable=False,\n",
    "                           name = 'embeddings')\n",
    "  embedded_sequences = embedding_layer(inp)\n",
    "\n",
    "  x = LSTM(params['output_count_lstm'], return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "  \n",
    "  x = GlobalMaxPool1D()(x)\n",
    "  \n",
    "  x = Dropout(params['dropout'])(x)\n",
    "  \n",
    "  x = Dense(params['output_count_dense'], activation=params['activation'], kernel_initializer='he_uniform')(x)\n",
    "  \n",
    "  x = Dropout(params['dropout'])(x)\n",
    "  \n",
    "  preds = Dense(6, activation=params['last_activation'], kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "  model = Model(inputs=inp, outputs=preds)\n",
    "\n",
    "  model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "\n",
    "  model_info=model.fit(x_train,y_train, epochs=params['epochs'], batch_size=params['batch_size'],  validation_data=(x_val, y_val))\n",
    "\n",
    "  return model_info, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary of Parameters.\n",
    "p={\n",
    "    'output_count_lstm': [40,50,60],\n",
    "    'output_count_dense': [30,40,50],\n",
    "    'batch_size': [32],\n",
    "    'epochs':[2],\n",
    "    'optimizer':['adam'],\n",
    "    'activation':['relu'],\n",
    "    'last_activation': ['sigmoid'],\n",
    "    'dropout':[0.1,0.2],\n",
    "    'loss': ['binary_crossentropy']   \n",
    "}\n",
    "\n",
    "#Initiating GridSearchCV.\n",
    "scan_results = talos.Scan(x=x_train,\n",
    "               y=y_train,\n",
    "               x_val=x_val,\n",
    "               y_val=y_val,\n",
    "               model=toxic_classifier,\n",
    "               params=p,\n",
    "               experiment_name='tcc',\n",
    "               print_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM Model.\n",
    "inp=Input(shape=(maxpadlen, ),dtype='int32')\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                           embedding_dim_fasttext,\n",
    "                           weights = [embedding_matrix_fasttext],\n",
    "                           input_length = maxpadlen,\n",
    "                           trainable=False,\n",
    "                           name = 'embeddings')\n",
    "embedded_sequences = embedding_layer(inp)\n",
    "x = LSTM(50, return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(40, activation=\"relu\", kernel_initializer='he_uniform')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "preds = Dense(1, activation=\"sigmoid\", kernel_initializer='glorot_uniform')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-27 11:24:27.227485: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8408/8408 [==============================] - ETA: 0s - loss: 0.3317 - accuracy: 0.8861"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba70051511e4c8293256bd71ec3b9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740058fce54b423d995effb26ccfffda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6680440771349863,Train WGA: {'male_0': 0.8786471483271189, 'male_1': 0.8277088225427709, 'female_0': 0.8770329132194129, 'female_1': 0.8471195232314314, 'LGBTQ_0': 0.8773223645335319, 'LGBTQ_1': 0.7393111638954869, 'christian_0': 0.8701485761452744, 'christian_1': 0.8988705213553744, 'muslim_0': 0.88041194273259, 'muslim_1': 0.7375662892360614, 'other_religions_0': 0.87399711993417, 'other_religions_1': 0.8331295843520783, 'black_0': 0.8802085343170926, 'black_1': 0.6843168957154406, 'white_0': 0.8865657446302607, 'white_1': 0.6680440771349863}\n",
      "0.6546913149633764,Val WGA: {'male_0': 0.8798218483236422, 'male_1': 0.8327387198321091, 'female_0': 0.8793046399755656, 'female_1': 0.8451875742658292, 'LGBTQ_0': 0.8787137204674885, 'LGBTQ_1': 0.7590940288263556, 'christian_0': 0.8711543194683731, 'christian_1': 0.9079120879120879, 'muslim_0': 0.8831669375435338, 'muslim_1': 0.70521327014218, 'other_religions_0': 0.8758428745983617, 'other_religions_1': 0.8306288032454361, 'black_0': 0.882558353243889, 'black_1': 0.6719128329297821, 'white_0': 0.8897738283742586, 'white_1': 0.6546913149633764}\n",
      "8408/8408 [==============================] - 357s 42ms/step - loss: 0.3317 - accuracy: 0.8861 - val_loss: 0.3174 - val_accuracy: 0.8887\n",
      "Epoch 2/2\n",
      "8407/8408 [============================>.] - ETA: 0s - loss: 0.3215 - accuracy: 0.8866"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77773cfce5bb48db972a09699b677699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa22a36afc24a718d72ec04634e237a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.705032336297494,Train WGA: {'male_0': 0.8871202367615831, 'male_1': 0.8529017108352902, 'female_0': 0.8864489634612576, 'female_1': 0.8632877165875731, 'LGBTQ_0': 0.8880507102349032, 'LGBTQ_1': 0.7371733966745844, 'christian_0': 0.8811019397441189, 'christian_1': 0.903508115790261, 'muslim_0': 0.8908947640777156, 'muslim_1': 0.745019349290526, 'other_religions_0': 0.8844811690933888, 'other_religions_1': 0.8371026894865525, 'black_0': 0.8901374535968697, 'black_1': 0.705032336297494, 'white_0': 0.893619719426171, 'white_1': 0.7278117139777219}\n",
      "0.6967312348668281,Val WGA: {'male_0': 0.8888778918718298, 'male_1': 0.8522560335781741, 'female_0': 0.8875003181552088, 'female_1': 0.8684433882193177, 'LGBTQ_0': 0.8891430139743385, 'LGBTQ_1': 0.7611530542210021, 'christian_0': 0.8820329805562392, 'christian_1': 0.9116483516483517, 'muslim_0': 0.8932899930345949, 'muslim_1': 0.7161137440758294, 'other_religions_0': 0.8863646648866362, 'other_religions_1': 0.8245436105476673, 'black_0': 0.8921613673956993, 'black_1': 0.6967312348668281, 'white_0': 0.8967456809963841, 'white_1': 0.7118939658179282}\n",
      "8408/8408 [==============================] - 363s 43ms/step - loss: 0.3215 - accuracy: 0.8866 - val_loss: 0.3163 - val_accuracy: 0.8890\n"
     ]
    }
   ],
   "source": [
    "model_1 = Model(inputs=inp, outputs=preds)\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.models.load_model(f'../models/1706353340.637279_new/0.89.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "8408/8408 [==============================] - ETA: 0s - loss: 0.3149 - accuracy: 0.8873"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bcd606e7bd458c835d42af7ac06665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fee006928aa4f2cbbace4c062ecd056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7001818916734034,Train WGA: {'male_0': 0.8902344207199826, 'male_1': 0.852230795035223, 'female_0': 0.8897780870640996, 'female_1': 0.8619081779053085, 'LGBTQ_0': 0.890744307760784, 'LGBTQ_1': 0.7399049881235155, 'christian_0': 0.8836112257531985, 'christian_1': 0.9078839105393074, 'muslim_0': 0.8924589546972762, 'muslim_1': 0.7683818259997134, 'other_religions_0': 0.8870602756634437, 'other_religions_1': 0.844437652811736, 'black_0': 0.8931203741577977, 'black_1': 0.7001818916734034, 'white_0': 0.8965007529523659, 'white_1': 0.7276919391543898}\n",
      "0.6803874092009685,Val WGA: {'male_0': 0.8911047878263021, 'male_1': 0.8467995802728226, 'female_0': 0.889663773575301, 'female_1': 0.8648786284162281, 'LGBTQ_0': 0.8906982594972898, 'LGBTQ_1': 0.75840768702814, 'christian_0': 0.8833620477479694, 'christian_1': 0.9138461538461539, 'muslim_0': 0.8939400975156722, 'muslim_1': 0.7331753554502369, 'other_religions_0': 0.8875186676924469, 'other_religions_1': 0.8377281947261663, 'black_0': 0.8942519757397537, 'black_1': 0.6803874092009685, 'white_0': 0.8984709191028761, 'white_1': 0.7087547959539588}\n",
      "8408/8408 [==============================] - 371s 44ms/step - loss: 0.3149 - accuracy: 0.8873 - val_loss: 0.3112 - val_accuracy: 0.8895\n",
      "Epoch 2/2\n",
      "8408/8408 [==============================] - ETA: 0s - loss: 0.3135 - accuracy: 0.8876"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b4ea50972b4242b1eb4f6bcc650d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a453a23325544a4e95322f787ae0c187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6963419563459984,Train WGA: {'male_0': 0.8908948785259251, 'male_1': 0.8522978866152298, 'female_0': 0.8902591991202522, 'female_1': 0.8632325350402825, 'LGBTQ_0': 0.8914886922622383, 'LGBTQ_1': 0.7358669833729217, 'christian_0': 0.8841683862979777, 'christian_1': 0.9088189094173087, 'muslim_0': 0.8926667293911026, 'muslim_1': 0.7760498781711337, 'other_religions_0': 0.8875860019657592, 'other_religions_1': 0.847799511002445, 'black_0': 0.893884434016871, 'black_1': 0.6963419563459984, 'white_0': 0.8974003328842038, 'white_1': 0.7236794825727632}\n",
      "0.6846246973365617,Val WGA: {'male_0': 0.892836818013114, 'male_1': 0.8474291710388248, 'female_0': 0.8910127516607702, 'female_1': 0.8682736377525038, 'LGBTQ_0': 0.8924593463394552, 'LGBTQ_1': 0.755662319835278, 'christian_0': 0.8850110755599311, 'christian_1': 0.9151648351648352, 'muslim_0': 0.8948456001857441, 'muslim_1': 0.7492890995260664, 'other_religions_0': 0.8890799656061908, 'other_religions_1': 0.8417849898580122, 'black_0': 0.8957682411321448, 'black_1': 0.6846246973365617, 'white_0': 0.9002434240068065, 'white_1': 0.7080572026508546}\n",
      "8408/8408 [==============================] - 363s 43ms/step - loss: 0.3135 - accuracy: 0.8876 - val_loss: 0.3087 - val_accuracy: 0.8901\n"
     ]
    }
   ],
   "source": [
    "model_info_1=model_1.fit(train_x,train_y, epochs=2, batch_size=32,  validation_data=(val_x, val_y),callbacks=[wga])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = str(time.time())\n",
    "path=os.path.join('../models',f'{t}_new')\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "model_path=f'{str(round(model_info_1.history[\"val_accuracy\"][-1],2))}'\n",
    "export_path = os.path.join(path,model_path)\n",
    "model_1.save(f'{export_path}.keras')\n",
    "json.dump(model_info_1.history,open(f'{export_path}.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_length\": max_length,\n",
    "    \"padding_type\": padding_type,\n",
    "    \"vocab_size\": vocab_size,\n",
    "    \"embedding_dim\": embedding_dim_fasttext,\n",
    "    \"trunc_type\": trunc_type,\n",
    "    \"oov_tok\": oov_tok,\n",
    "    'model_accuracy': f'{str(round(model_info_1.history[\"val_accuracy\"][-1],2))}'\n",
    "}\n",
    "params_json = json.dumps(params, indent=4)\n",
    "with open(f'{path}/params.json', 'w') as f:\n",
    "    f.write(params_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Adding Input Parameters to the Function.\n",
    "# def toxic_classifier(x_train,y_train,x_val,y_val,params):\n",
    "\n",
    "#   inp=Input(shape=(maxpadlen, ),dtype='int32')\n",
    "\n",
    "#   embedding_layer = Embedding(len(word_index) + 1,\n",
    "#                            embedding_dim_fasttext,\n",
    "#                            weights = [embedding_matrix_fasttext],\n",
    "#                            input_length = maxpadlen,\n",
    "#                            trainable=False,\n",
    "#                            name = 'embeddings')\n",
    "#   embedded_sequences = embedding_layer(inp)\n",
    "\n",
    "#   x = LSTM(params['output_count_lstm'], return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "\n",
    "#   x = Conv1D(filters=params['filters'], kernel_size=params['kernel_size'], padding='same', activation='relu', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "#   x = MaxPooling1D(params['pool_size'])(x)\n",
    "  \n",
    "#   x = GlobalMaxPool1D()(x)\n",
    "  \n",
    "#   x = BatchNormalization()(x)\n",
    "  \n",
    "#   x = Dense(params['output_1_count_dense'], activation=params['activation'], kernel_initializer='he_uniform')(x)\n",
    "  \n",
    "#   x = Dropout(params['dropout'])(x)\n",
    "\n",
    "#   x = Dense(params['output_2_count_dense'], activation=params['activation'], kernel_initializer='he_uniform')(x)\n",
    "  \n",
    "#   x = Dropout(params['dropout'])(x)\n",
    "  \n",
    "#   preds = Dense(6, activation=params['last_activation'], kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "#   model = Model(inputs=inp, outputs=preds)\n",
    "\n",
    "#   model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "\n",
    "#   model_info=model.fit(x_train,y_train, epochs=params['epochs'], batch_size=params['batch_size'],  validation_data=(x_val, y_val))\n",
    "\n",
    "#   return model_info, model\n",
    "\n",
    "# #Creating a dictionary of Parameters.\n",
    "# p={\n",
    "#     'output_count_lstm': [50,60],\n",
    "#     'output_1_count_dense': [40,50],\n",
    "#     'output_2_count_dense': [30,40],\n",
    "#     'filters' : [64],\n",
    "#     'kernel_size' : [3],\n",
    "#     'batch_size': [32],\n",
    "#     'pool_size': [3],\n",
    "#     'epochs':[2],\n",
    "#     'optimizer':['adam'],\n",
    "#     'activation':['relu'],\n",
    "#     'last_activation': ['sigmoid'],\n",
    "#     'dropout':[0.1,0.2],\n",
    "#     'loss': ['binary_crossentropy']   \n",
    "# }\n",
    "\n",
    "# #Initiating GridSearchCV.\n",
    "# scan_results = talos.Scan(x=x_train,\n",
    "#                y=y_train,\n",
    "#                x_val=x_val,\n",
    "#                y_val=y_val,\n",
    "#                model=toxic_classifier,\n",
    "#                params=p,\n",
    "#                experiment_name='tcc',\n",
    "#                print_params=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the LSTM-CNN Model.\n",
    "# inp=Input(shape=(maxpadlen, ),dtype='int32')\n",
    "# embedding_layer = Embedding(len(word_index) + 1,\n",
    "#                            embedding_dim_fasttext,\n",
    "#                            weights = [embedding_matrix_fasttext],\n",
    "#                            input_length = maxpadlen,\n",
    "#                            trainable=False,\n",
    "#                            name = 'embeddings')\n",
    "# embedded_sequences = embedding_layer(inp)\n",
    "# x = LSTM(50, return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "# x = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_uniform')(x)\n",
    "# x = MaxPooling1D(3)(x)\n",
    "# x = GlobalMaxPool1D()(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dense(40, activation=\"relu\", kernel_initializer='he_uniform')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Dense(30, activation=\"relu\", kernel_initializer='he_uniform')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# preds = Dense(6, activation=\"sigmoid\", kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
