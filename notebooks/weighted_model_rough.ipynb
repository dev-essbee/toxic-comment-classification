{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x=np.load('./processed/train_padded.npy')\n",
    "# train_z\n",
    "# train_y=np.load('./processed/train_y.npy')\n",
    "# val_x=np.load('./processed/val_padded.npy')\n",
    "# val_z=pd.read_csv('./')\n",
    "# val_y=np.load('./processed/val_y.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some dummy data for illustration purposes\n",
    "np.random.seed(42)\n",
    "num_samples = 1000\n",
    "max_length = 10\n",
    "num_identity_categories = 3  # Adjust this based on the number of identity categories\n",
    "x = np.random.rand(num_samples, max_length)  # Random features for text samples\n",
    "z1 = np.random.choice(['male', 'female'], size=num_samples)  # Dummy identity information category 1\n",
    "z2 = np.random.choice(['young', 'old'], size=num_samples)  # Dummy identity information category 2\n",
    "z3 = np.random.choice(['student', 'professional'], size=num_samples)  # Dummy identity information category 3\n",
    "y = np.random.randint(2, size=num_samples)  # Dummy labels (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess text data and split the dataset\n",
    "# tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "# tokenizer.fit_on_texts(x)\n",
    "# x_seq = tokenizer.texts_to_sequences(x)\n",
    "# x_padded = tf.keras.preprocessing.sequence.pad_sequences(x_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "# Encode each identity information category separately\n",
    "z1_encoded = np.array([1 if identity == 'female' else 0 for identity in z1])\n",
    "z2_encoded = np.array([1 if identity == 'old' else 0 for identity in z2])\n",
    "z3_encoded = np.array([1 if identity == 'professional' else 0 for identity in z3])\n",
    "\n",
    "# x_train, x_test, z1_train, z1_test, z2_train, z2_test, z3_train, z3_test, y_train, y_test = train_test_split(\n",
    "#     x_padded, z1_encoded, z2_encoded, z3_encoded, y, test_size=0.2, random_state=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train classifiers and estimate P(y|z) using a simple neural network\n",
    "embedding_dim = 8\n",
    "\n",
    "text_input = tf.keras.layers.Input(shape=(max_length,))\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_length)(text_input)\n",
    "flatten_text = tf.keras.layers.Flatten()(embedding_layer)\n",
    "\n",
    "# Create separate embedding layers for each identity information category\n",
    "identity_input1 = tf.keras.layers.Input(shape=(1,))\n",
    "embedding_identity1 = tf.keras.layers.Embedding(input_dim=2, output_dim=embedding_dim)(identity_input1)\n",
    "flatten_identity1 = tf.keras.layers.Flatten()(embedding_identity1)\n",
    "\n",
    "identity_input2 = tf.keras.layers.Input(shape=(1,))\n",
    "embedding_identity2 = tf.keras.layers.Embedding(input_dim=2, output_dim=embedding_dim)(identity_input2)\n",
    "flatten_identity2 = tf.keras.layers.Flatten()(embedding_identity2)\n",
    "\n",
    "identity_input3 = tf.keras.layers.Input(shape=(1,))\n",
    "embedding_identity3 = tf.keras.layers.Embedding(input_dim=2, output_dim=embedding_dim)(identity_input3)\n",
    "flatten_identity3 = tf.keras.layers.Flatten()(embedding_identity3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all embeddings\n",
    "concatenated_embeddings = tf.keras.layers.concatenate([flatten_text, flatten_identity1, flatten_identity2, flatten_identity3])\n",
    "\n",
    "dense_layer = tf.keras.layers.Dense(16, activation='relu')(concatenated_embeddings)\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(dense_layer)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[text_input, identity_input1, identity_input2, identity_input3], outputs=output_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([x_train, z1_train, z2_train, z3_train], y_train, epochs=5, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Calculate instance weights\n",
    "probabilities = model.predict([x_train, z1_train, z2_train, z3_train]).flatten()\n",
    "prior_prob_y = np.mean(y_train)\n",
    "weights = prior_prob_y / probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train models using calculated instance weights\n",
    "weighted_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "weighted_model.fit([x_train, z_train], y_train, epochs=5, batch_size=32, sample_weight=weights, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the model\n",
    "y_pred_weighted = (weighted_model.predict([x_test, z_test]) > 0.5).astype(int).flatten()\n",
    "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "print(\"Accuracy with instance weights:\", accuracy_weighted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
