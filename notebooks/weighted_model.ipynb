{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../params.json', 'r') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "max_length = params['max_length']\n",
    "padding_type = params['padding_type']\n",
    "vocab_size = params['vocab_size']\n",
    "embedding_dim = params['embedding_dim']\n",
    "trunc_type = params['trunc_type']\n",
    "oov_tok = params['oov_tok']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.load('../processed/train_padded.npy')\n",
    "train_y=np.load('../processed/train_y.npy')\n",
    "val_x=np.load('../processed/val_padded.npy')\n",
    "val_y=np.load('../processed/val_y.npy')\n",
    "word_index = json.load(open('../processed/word_index.json'))\n",
    "train_meta=pd.read_csv('../processed/train_meta.csv')\n",
    "val_meta=pd.read_csv('../processed/val_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['male', 'female', 'LGBTQ', 'christian', 'muslim', 'other_religions',\n",
       "       'black', 'white', 'identity_any', 'severe_toxicity', 'obscene',\n",
       "       'threat', 'insult', 'identity_attack', 'sexual_explicit', 'y',\n",
       "       'from_source_domain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def encode_labels(meta):\n",
    "#     # example:\n",
    "#     # female:1\n",
    "#     # male:3\n",
    "#     # lgbtq:5\n",
    "#     # male+female:4\n",
    "#     # male+lgbtq:8\n",
    "#     # female+lgbtq:6\n",
    "#     # male+female+lgbtq: 9\n",
    "#     def encode_values(train_z):\n",
    "#         categories=train_z.shape[1]\n",
    "#         for i in range(categories):\n",
    "#             train_z.iloc[:,i]=train_z.iloc[:,i].replace(1,2*i+1)\n",
    "#         return(train_z)\n",
    "#     z_gen=meta.iloc[:,:3]\n",
    "#     z_rel=meta.iloc[:,3:6]\n",
    "#     z_col=meta.iloc[:,6:8]\n",
    "#     z_gen_encoded=encode_values(z_gen).sum(axis=1)\n",
    "#     z_rel_encoded=encode_values(z_rel).sum(axis=1)\n",
    "#     z_col_encoded=encode_values(z_col).sum(axis=1)\n",
    "#     return ([z_gen_encoded.values,z_rel_encoded.values,z_col_encoded.values])\n",
    "# train_z=encode_labels(train_meta)\n",
    "# val_z=encode_labels(val_meta)\n",
    "# # Step 3: Train classifiers and estimate P(y|z) using a simple neural network\n",
    "# embedding_dim = 16\n",
    "\n",
    "# text_input = tf.keras.layers.Input(shape=(max_length,))\n",
    "# embedding_layer = tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_length)(text_input)\n",
    "# flatten_text = tf.keras.layers.Flatten()(embedding_layer)\n",
    "\n",
    "# # Create separate embedding layers for each identity information category\n",
    "# meta_gen = tf.keras.layers.Input(shape=(1,))\n",
    "# embedding_gen = tf.keras.layers.Embedding(input_dim=7, output_dim=embedding_dim)(meta_gen)\n",
    "# flatten_gen = tf.keras.layers.Flatten()(embedding_gen)\n",
    "\n",
    "# meta_rel = tf.keras.layers.Input(shape=(1,))\n",
    "# embedding_rel = tf.keras.layers.Embedding(input_dim=7, output_dim=embedding_dim)(meta_rel)\n",
    "# flatten_gen = tf.keras.layers.Flatten()(embedding_rel)\n",
    "\n",
    "# meta_col = tf.keras.layers.Input(shape=(1,))\n",
    "# embedding_col = tf.keras.layers.Embedding(input_dim=3, output_dim=embedding_dim)(meta_col)\n",
    "# flatten_col = tf.keras.layers.Flatten()(embedding_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find values to be used for encoding:\n",
    "import itertools\n",
    "\n",
    "def all_sums(lst):\n",
    "    sums = set()\n",
    "    for r in range(2, len(lst) + 1):\n",
    "        for combination in itertools.combinations(lst, r):\n",
    "            sums.add(sum(combination))\n",
    "    return sums\n",
    "\n",
    "# Test the function\n",
    "values=[2*i+5 for i in range(8)]\n",
    "all_values=all_sums(values)\n",
    "for i in values:\n",
    "    if i in all_values:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(meta):\n",
    "    # example:\n",
    "    # female:1\n",
    "    # male:3\n",
    "    # lgbtq:5\n",
    "    # male+female:4\n",
    "    # male+lgbtq:8\n",
    "    # female+lgbtq:6\n",
    "    # male+female+lgbtq: 9 and so on\n",
    "    def encode_values(train_z):\n",
    "        categories=train_z.shape[1]\n",
    "        for i in range(categories):\n",
    "            train_z.iloc[:,i]=train_z.iloc[:,i].replace(1,2*i+5)\n",
    "        return(train_z)\n",
    "    z=meta.iloc[:,:8]\n",
    "    z_encoded=encode_values(z)\n",
    "    z_encode=z_encoded.sum(axis=1)\n",
    "    return (z_encode.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_z=encode_labels(train_meta)\n",
    "val_z=encode_labels(val_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(train_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value\n",
       "0        160916\n",
       "5         11395\n",
       "7         18983\n",
       "9          4378\n",
       "11        17649\n",
       "          ...  \n",
       "84            2\n",
       "85            1\n",
       "87            6\n",
       "91            1\n",
       "96            2\n",
       "Name: count, Length: 78, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'value':train_z}).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154222"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 18:26:48.909230: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-01-23 18:26:48.909258: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-01-23 18:26:48.909265: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-01-23 18:26:48.909302: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-23 18:26:48.909319: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train classifiers and estimate P(y|z) using a simple neural network\n",
    "embedding_dim = 17\n",
    "\n",
    "text_input = tf.keras.layers.Input(shape=(max_length,))\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(word_index) + 1, output_dim=embedding_dim, input_length=max_length)(text_input)\n",
    "flatten_text = tf.keras.layers.Flatten()(embedding_layer)\n",
    "\n",
    "meta = tf.keras.layers.Input(shape=(1,))\n",
    "embedding_meta = tf.keras.layers.Embedding(input_dim=78, output_dim=embedding_dim)(meta)\n",
    "flatten_meta = tf.keras.layers.Flatten()(embedding_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all embeddings\n",
    "concatenated_embeddings = tf.keras.layers.concatenate([flatten_text, flatten_meta])\n",
    "\n",
    "dense_layer = tf.keras.layers.Dense(16, activation='relu')(concatenated_embeddings)\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(dense_layer)\n",
    "\n",
    "prob_model = tf.keras.models.Model(inputs=[text_input, flatten_meta], outputs=output_layer)\n",
    "\n",
    "prob_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 18:26:54.003718: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8408/8408 [==============================] - 190s 23ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 2.5468e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "8408/8408 [==============================] - 179s 21ms/step - loss: 3.9041e-06 - accuracy: 1.0000 - val_loss: 4.8274e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "8408/8408 [==============================] - 174s 21ms/step - loss: 4.2196e-08 - accuracy: 1.0000 - val_loss: 9.3351e-09 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "8408/8408 [==============================] - 177s 21ms/step - loss: 5.9508e-10 - accuracy: 1.0000 - val_loss: 1.6596e-09 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "8408/8408 [==============================] - 173s 21ms/step - loss: 5.4501e-11 - accuracy: 1.0000 - val_loss: 9.8418e-10 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "prob_history=prob_model.fit([train_x,train_meta], train_y, epochs=5, batch_size=32,validation_data=([val_x,val_meta], val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8408/8408 [==============================] - 17s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "probabilities = prob_model.predict([train_x, train_meta]).flatten()\n",
    "prior_prob_y = np.mean(train_y)\n",
    "weights = prior_prob_y / probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000000e+00, 1.0000000e+00, 1.0000000e+00, ..., 6.9287011e-12,\n",
       "       3.4749542e-10, 7.3590889e-10], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11342306076859317"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_prob_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269037,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = str(time.time())\n",
    "path=os.path.join('../models',t)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "accuracy_path=str(round(prob_history.history['val_accuracy'][-1],2))\n",
    "export_path = os.path.join(path,f'weighted_{accuracy_path}')\n",
    "prob_model.save(f'{export_path}.keras')\n",
    "json.dump(prob_history.history,open(f'{export_path}.json','w'))\n",
    "with open(f'{export_path}_weights.npy','wb') as f:\n",
    "    np.save(f, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
